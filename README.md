
# Neural Network Implementation from Scratch

## Overview

This project is a hands-on implementation of a simple neural network built entirely from scratch using Python. The primary goal is to reinforce foundational deep learning concepts by manually coding the key components of a neural network, including forward propagation, backpropagation, and optimization techniques. The model is trained on the MNIST dataset, a benchmark in the field of computer vision, to recognize handwritten digits.

## Features

- **Manual Implementation**: All core components such as activation functions, loss functions, and gradient calculations are implemented from scratch.
- **Training on MNIST**: The network is trained on the MNIST dataset, achieving an accuracy of **95%**.
- **Custom Optimization**: Gradient descent and other optimizations are custom-coded to ensure a thorough understanding of the underlying mechanics.
- **Fully Documented**: The code is well-commented and structured to be educational for those looking to understand neural networks at a deeper level.

## Getting Started

### Prerequisites

To run the code, you'll need:

- Python 3.x
- Numpy
- Matplotlib (for visualizing training progress)
- MNIST dataset (automatically downloaded via script)

### Installation

1. **Clone the Repository**:
   \`\`\`bash
   git clone https://github.com/ShadanAnwar/Neural-Network-Implementation-from-scratch.git
   cd Neural-Network-Implementation-from-scratch
   \`\`\`

2. **Install Dependencies**:
   Install the required packages using pip:
   \`\`\`bash
   pip install numpy matplotlib
   \`\`\`

3. **Run the Project**:
   Execute the main script to train and evaluate the neural network:
   \`\`\`bash
   python main.py
   \`\`\`

### Usage

The \`main.py\` script is the entry point for training the neural network on the MNIST dataset. The training progress and accuracy will be displayed in the console, and visualizations will be generated to illustrate the learning curve.

### Code Structure

- \`main.py\`: The primary script to run the training and evaluation of the neural network.
- \`neural_network.py\`: Contains the implementation of the neural network, including forward and backward propagation.
- \`utils.py\`: Utility functions for data processing, initialization, and other helper methods.
- \`README.md\`: Documentation for the project.

## Results

- **Accuracy**: The neural network achieves an accuracy of **95%** on the MNIST dataset.
- **Learning Curve**: The model's performance improves steadily with each epoch, as visualized in the learning curve generated by Matplotlib.

## Contributing

Contributions are welcome! Please fork this repository, make your changes, and submit a pull request. Whether it's improving the code, fixing bugs, or adding new features, your contributions are highly valued.

## Acknowledgements

- **MNIST Dataset**: Thanks to Yann LeCun and the team for providing the MNIST dataset.
- **Inspiration**: Inspired by the need to understand deep learning at a deeper level by coding neural networks from scratch.

## Contact

For any inquiries or issues, please contact me via LinkedIn or by email at shadan.anwar2005@gmail.com. Alternatively, you can open an issue in the repository.
